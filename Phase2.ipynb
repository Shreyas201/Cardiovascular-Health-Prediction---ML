{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0225ae68",
   "metadata": {},
   "source": [
    "# Predicting Heart Failure Using Clinical Records\n",
    "\n",
    "## Phase 2 : Predictive modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a310bd",
   "metadata": {},
   "source": [
    "#### Group Number:  45\n",
    "***\n",
    "**Name(s) & ID(s) of Group Members:** \n",
    "* Shreyas Ainapur, s3928704 \n",
    "* Saisiva Devulapalli, s3931923\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b85dbe",
   "metadata": {},
   "source": [
    "# Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974921e8",
   "metadata": {},
   "source": [
    "1. [Introduction](#introduction) <br>\n",
    "     1.1. [Phase 1 Summary](#Phase1summary) <br>\n",
    "     1.2. [Report Overview](#Reportoverview) <br>\n",
    "     1.3. [Overview of Methodology](#Overviewofmethodology) <br>\n",
    "2. [Predictive Modelling](#Predictivemodelling)  <br>\n",
    "     2.1. [Feature Selection (FS)](#fs) <br>\n",
    "     2.2. [Model Fitting & Tuning](#Modelfittingtuning) <br>\n",
    "     2.3. [Neural Network Model Fitting & Tuning](#NN) <br>\n",
    "     2.4. [Model Comparison](#Modelcomparison) <br>   \n",
    "3. [Critique & Limitations](#Critique) <br>\n",
    "4. [Summary & Conclusions](#Summary) <br>\n",
    "     4.1. [Project Summary](#Projectsummary) <br>\n",
    "     4.2. [Summary of Findings](#Summaryoffindings) <br>\n",
    "     4.3. [Conclusions](#Conclusions) <br>\n",
    "5. [References](#References) <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac2c511",
   "metadata": {},
   "source": [
    "## 1. Introduction <a name=\"introduction\"></a>\n",
    "### 1.1. Phase 1 Summary : <a name=\"Phase1summary\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d91eeff",
   "metadata": {},
   "source": [
    "Using clinical record data, predicting the probability of heart failure in a patient has numerous real-time applications. The data provided details of the health problems of heart disease patients and includes features such as age, gender, smoking habits, serum sodium level, ejection fraction, creatinine phosphokinase levels, and follow-up time length. An application can be made which provides analysis and insights using the data & can be used by healthcare providers in hospitals or by individuals for early detection, thereby reducing the risk of heart failure-related deaths.\n",
    "\n",
    "During the first phase of our project, we took performed several important data prepartion steps. First, we clearly defined the dataset's source and provided a summary and the background information related to the data collection. We then briefly described each attribute, including its data type and unit of measurement, and identified the target feature, which is predicting the DEATH_EVENT using the dataset attributes.\n",
    "\n",
    "Next, we conducted data cleaning and preprocessing tasks. Although we considered dropping some of the dataset's irrelevant features, we ultimately retained all 13 columns because they were essential as they are related to cardiovascular diseases  and these are clinical observations . We also performed exploratory data analysis, checking for null values and replacing binary values with appropriate nominal categorical objects for better readability. \n",
    "\n",
    "To ensure data accuracy, we ran boxplots to identify outliers and used the z-score function to remove them. We also checked for any anomalies in the data and rounded the Age column to the nearest whole number for better analysis and readability. Finally, we converted the attribute data types, resulting in a thoroughly cleaned and processed dataset.\n",
    "\n",
    "During the next task, we created various visual representations to analyze our collected data. These visualizations included univariate, bivariate, and multivariate graphs. We used histograms to show the distribution of age and ejection percentage and violin plots to represent the distribution of serum sodium. Bar plots were used to compare follow-up time with the death event and smoking habits with age. Line graphs were used to compare age and ejection percentage. Additionally, we used box plots to show how serum sodium varied according to sex and death event, and scatter plots to display the correlation between the follow-up duration, creatinine phosphokinase levels, and the death event."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2379c74",
   "metadata": {},
   "source": [
    "### 1.2. Report Overview : <a name=\"Reportoverview\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc053e4a",
   "metadata": {},
   "source": [
    "Our goal for Phase 2 of this project is to develop a model that can predict which patients are at a higher risk of death due to heart failure. To achieve this, we will use pre-processed and cleaned data from Phase 1. We will identify the key features, explore different machine learning algorithms, evaluate their performance, and ensure fairness while assessing limitations. \n",
    "\n",
    "To begin, we will select features based on the trends observed during our Phase 1 analysis. Then, we will encode categorical attributes and scale numerical variables using the Min-Max scalar. Finally, we will build at least four different machine-learning models to predict the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1291fe2f",
   "metadata": {},
   "source": [
    "### 1.3. Overview of Methodology : <a name=\"Overviewofmethodology\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eebcb6d",
   "metadata": {},
   "source": [
    "/?/ Write while implementing methods.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663c9e06",
   "metadata": {},
   "source": [
    "## 2. Predictive Modelling <a name=\"Predictivemodelling\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6038d3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing all the required packages\n",
    "from io import StringIO\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None) \n",
    "\n",
    "\n",
    "#filter warnings in output cells\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.layers import ELU, PReLU, LeakyReLU\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee36351",
   "metadata": {},
   "source": [
    "We are using the pre-processed, cleaned data from the Phase1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd7fb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb228a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading the data from local directory\n",
    "heart_data = pd.read_csv(\"Phase1_processed_data.csv\")\n",
    "heart_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7cee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysisng the correlation between different features in the dataset\n",
    "hear_data_corr = heart_data.corr()\n",
    "print(hear_data_corr.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c840fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting plot size\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(12, 8)\n",
    "    \n",
    "# plotting correlation heatmap\n",
    "fig = sns.heatmap(hear_data_corr.corr(), annot=True)\n",
    "\n",
    "# displaying heatmap\n",
    "plt.title('Figure 1: Correlation heatmap among various clinical features', fontsize = 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8b984a",
   "metadata": {},
   "source": [
    "#### One Hot Encoding:<br>\n",
    "Since the features \"sex\", \"smoking\", and \"DEATH_EVENT\" have binary categorical variables that is the unique values present in these 3 categorical columns are only 2 we convert these columns into single binary column instead of performing one hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9a937a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(heart_data['sex'].unique())\n",
    "print(heart_data['smoking'].unique())\n",
    "print(heart_data['DEATH_EVENT'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952eceff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform label encoding\n",
    "label_encoder = LabelEncoder()\n",
    "heart_data['sex'] = label_encoder.fit_transform(heart_data['sex'])\n",
    "heart_data['smoking'] = label_encoder.fit_transform(heart_data['smoking'])\n",
    "heart_data['DEATH_EVENT'] = label_encoder.fit_transform(heart_data['DEATH_EVENT'])\n",
    "\n",
    "heart_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8477a68a",
   "metadata": {},
   "source": [
    "In the above step, the transformation has taken place as follows:<br>\n",
    "\"sex\"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: male = 0, female = 1<br>\n",
    "\"smoking\"&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;: non-smoker = 0, smoker = 1<br>\n",
    "\"DEATH_EVENT\": Deceased = 0, Non-Deceased = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be37a7e0",
   "metadata": {},
   "source": [
    "#### Separating the  target variable from dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e87abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = heart_data.drop(columns='DEATH_EVENT')\n",
    "target = heart_data['DEATH_EVENT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937124d4",
   "metadata": {},
   "source": [
    "### 2.1. Feature Selection (FS) : <a name=\"fs\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac21b21",
   "metadata": {},
   "source": [
    "Comparing the importance of each features with one another using Random Forest Importance (RFI). This is for a fast ranking of all the characteristics to gain insights int the current scenario. During the hyperparameter tuning phase, we will include RFI as part of the pipeline and we will search over 6, 8, and the full set of 12 features to determine which number of features works best with each classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26160e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = 12\n",
    "model_rfi = RandomForestClassifier(n_estimators=100)\n",
    "model_rfi.fit(data, target)\n",
    "fs_indices_rfi = np.argsort(model_rfi.feature_importances_)[::-1][0:num_features]\n",
    "\n",
    "best_features_rfi = heart_data.columns[fs_indices_rfi].values\n",
    "best_features_rfi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a48bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances_rfi = model_rfi.feature_importances_[fs_indices_rfi]\n",
    "feature_importances_rfi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42b494e",
   "metadata": {},
   "source": [
    "#### Visulaizing the importance of all 12 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50ea963",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "def plot_imp(best_features, scores, method_name):   \n",
    "    plt.barh(best_features, scores)\n",
    "    plt.title(method_name + ' Feature Importances')\n",
    "    plt.xlabel(\"Importance\")\n",
    "    plt.ylabel(\"Features\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0f59b5",
   "metadata": {},
   "outputs": [],
   "source": [
    " plt.figure(figsize=(10, 6))\n",
    "plot_imp(best_features_rfi, feature_importances_rfi, 'Random Forest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc506e4",
   "metadata": {},
   "source": [
    "In the above plot, length of the bar represnts the importance of the feature. Longer the length higher the importance.\n",
    "Here we see that the most important feature to determine if the patient is deceased(i.e if the patient dies) is \"time\" followed by \"serum_creatinine\", and \"ejection_fraction\". Here time implies the follow up period of patient in days. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d82929",
   "metadata": {},
   "source": [
    "### 2.1.1 Splitting data into Train-Test data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc139c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_sample = pd.DataFrame(data).values\n",
    "target_sample = pd.DataFrame(target).values\n",
    "\n",
    "print(Data_sample.shape)\n",
    "print(target_sample.shape)\n",
    "\n",
    "## Using the train_test_split function data is divided into training and testing sets 80:20 ratio respectively\n",
    "Data_sample_train, Data_sample_test, \\\n",
    "target_sample_train, target_sample_test = train_test_split(Data_sample, target_sample, \n",
    "                                                    test_size = 0.2, random_state=999,\n",
    "                                                    stratify = target_sample)\n",
    "\n",
    "print(Data_sample_train.shape)\n",
    "print(Data_sample_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fec5a87",
   "metadata": {},
   "source": [
    "### 2.2. Model Fitting & Tuning : <a name=\"Modelfittingtuning\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e056bf2",
   "metadata": {},
   "source": [
    "Using the 80:20 ratio, the data set is divided into training and testing data sets repectively. Which imples, 223 observations will be used for training and remaining 56 observartions will be used for testing.<br>\n",
    "Each model's hyperparameters are tuned using the 5-fold stratified cross-validation assessment approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecf1864",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_method = StratifiedKFold(n_splits=5, shuffle=True, random_state=999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65051e5c",
   "metadata": {},
   "source": [
    "### 2.2.1 K-Nearest Neighbors :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7ea843",
   "metadata": {},
   "source": [
    "Using Pipeline, we stack feature selection and grid search for KNN hyperparameter tuning via cross-validation.<br>\n",
    "The KNN hyperparameters are as follows:\n",
    "- number of neighbors (n_neighbors) and\n",
    "- the distance metric p\n",
    "\n",
    "For feature selection, we use the powerful Random Forest Importance (RFI) method with 100 estimators.To make RFI feature selection as part of the pipeline we define the custom RFIFeatureSelector() class below to pass in RFI as a \"step\" to the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268860be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# custom function for RFI feature selection inside a pipeline\n",
    "# here we use n_estimators=100\n",
    "class RFIFeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    # class constructor \n",
    "    # make sure class attributes end with a \"_\"\n",
    "    # per scikit-learn convention to avoid errors\n",
    "    def __init__(self, n_features_=8):\n",
    "        self.n_features_ = n_features_\n",
    "        self.fs_indices_ = None\n",
    "\n",
    "    # override the fit function\n",
    "    def fit(self, X, y):\n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        from numpy import argsort\n",
    "        model_rfi = RandomForestClassifier(n_estimators=100)\n",
    "        model_rfi.fit(X, y)\n",
    "        self.fs_indices_ = argsort(model_rfi.feature_importances_)[::-1][0:self.n_features_] \n",
    "        return self \n",
    "    \n",
    "    # override the transform function\n",
    "    def transform(self, X, y=None):\n",
    "        return X[:, self.fs_indices_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9924eb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pipe_KNN = Pipeline(steps=[('rfi_fs', RFIFeatureSelector()), \n",
    "                           ('knn', KNeighborsClassifier())])\n",
    "\n",
    "params_pipe_KNN = {'rfi_fs__n_features_': [6, 8, heart_data.shape[1]],\n",
    "                   'knn__n_neighbors': [1, 3, 6, 9, 12],\n",
    "                   'knn__p': [1, 2]}\n",
    "\n",
    "gs_pipe_KNN = GridSearchCV(estimator=pipe_KNN, \n",
    "                           param_grid=params_pipe_KNN, \n",
    "                           cv=cv_method,\n",
    "                           refit=True,\n",
    "                           n_jobs=-2,\n",
    "                           scoring='roc_auc',\n",
    "                           verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6e894d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gs_pipe_KNN.fit(Data_sample_train, target_sample_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8833eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_pipe_KNN.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c212930",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_pipe_KNN.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aef0bd",
   "metadata": {},
   "source": [
    "We observe that the optimal KNN model has a mean AUC score of 0.779. The best performing KNN selected 6 features with 9 nearest neighbors and  𝑝=2, which is the Euclidean distance.\n",
    "\n",
    "Even though these are the best values, below we can see if there is any significant difference with different hyperparatmeter values. For this, we will format the grid search outputs as a Pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7395fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom function to format the search results as a Pandas data frame\n",
    "def get_search_results(gs):\n",
    "\n",
    "    def model_result(scores, params):\n",
    "        scores = {'mean_score': np.mean(scores),\n",
    "             'std_score': np.std(scores),\n",
    "             'min_score': np.min(scores),\n",
    "             'max_score': np.max(scores)}\n",
    "        return pd.Series({**params,**scores})\n",
    "\n",
    "    models = []\n",
    "    scores = []\n",
    "\n",
    "    for i in range(gs.n_splits_):\n",
    "        key = f\"split{i}_test_score\"\n",
    "        r = gs.cv_results_[key]        \n",
    "        scores.append(r.reshape(-1,1))\n",
    "\n",
    "    all_scores = np.hstack(scores)\n",
    "    for p, s in zip(gs.cv_results_['params'], all_scores):\n",
    "        models.append((model_result(s, p)))\n",
    "\n",
    "    pipe_results = pd.concat(models, axis=1).T.sort_values(['mean_score'], ascending=False)\n",
    "\n",
    "    columns_first = ['mean_score', 'std_score', 'max_score', 'min_score']\n",
    "    columns = columns_first + [c for c in pipe_results.columns if c not in columns_first]\n",
    "\n",
    "    return pipe_results[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c433cc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_KNN = get_search_results(gs_pipe_KNN)\n",
    "results_KNN.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1032549d",
   "metadata": {},
   "source": [
    "We observe that there is some difference between the hyperparameter combinations. Especially in the second observation we can see there is 6% of accracy drop. The worst model has AUC score of 0.687 while the best model has AUC score of 0.779.<br>\n",
    "Below is the visualization of the results of the grid search corresponding to 6 selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6145b14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_KNN_6_features = results_KNN[results_KNN['rfi_fs__n_features_'] == 6.0]\n",
    "\n",
    "for i in results_KNN_6_features['knn__p'].unique():\n",
    "    temp = results_KNN_6_features[results_KNN_6_features['knn__p'] == i]\n",
    "    plt.plot(temp['knn__n_neighbors'], temp['mean_score'], marker = '.', label = i)\n",
    "    \n",
    "plt.legend(title = \"p\")\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.ylabel(\"AUC Score\")\n",
    "plt.title(\"KNN Performance Comparison with 6 Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d145e9a0",
   "metadata": {},
   "source": [
    "### 2.2.2 Naive Bayes(NB) :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb078ca",
   "metadata": {},
   "source": [
    "Similar to KNN, we use pipeline methodology for NB.<br>\n",
    "The hyperparameter for NB is :<br>\n",
    "var_smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c3e280",
   "metadata": {},
   "source": [
    "We optimize var_smoothing. By default, the var_smoothing parameter's value is 10−9. We conduct the grid search in the logspace (over the powers of 10) sourced from NumPy. We start with 10 and end with 10−3 with 200 different values, but we perform a random search over only 20 different values. Since NB requires each descriptive feature to follow a Gaussian distribution, we first perform a power transformation on the input data before model fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4553cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "X_train_transformed = PowerTransformer().fit_transform(Data_sample_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e407a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "pipe_NB = Pipeline([('rfi_fs', RFIFeatureSelector()), \n",
    "                     ('nb', GaussianNB())])\n",
    "\n",
    "params_pipe_NB = {'rfi_fs__n_features_': [6, 8, heart_data.shape[1]],\n",
    "                  'nb__var_smoothing': np.logspace(1,-3, num=200)}\n",
    "\n",
    "n_iter_search = 20\n",
    "gs_pipe_NB = RandomizedSearchCV(estimator=pipe_NB, \n",
    "                          param_distributions=params_pipe_NB, \n",
    "                          cv=cv_method,\n",
    "                          refit=True,\n",
    "                          n_jobs=-2,\n",
    "                          scoring='roc_auc',\n",
    "                          n_iter=n_iter_search,\n",
    "                          verbose=1) \n",
    "\n",
    "gs_pipe_NB.fit(X_train_transformed, target_sample_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d10025a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_pipe_NB.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b844e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_pipe_NB.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de13930",
   "metadata": {},
   "source": [
    "The optimal NB model yiels an AUC score of 0.918 (with 6 features) - significantly higher than that of KNN.\n",
    "\n",
    "Even though these are the best values, below we can see if there is any significant difference with different hyperparatmeter values. For this, we will format the grid search outputs as a Pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871b6879",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_NB = get_search_results(gs_pipe_NB)\n",
    "results_NB.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ecacf8",
   "metadata": {},
   "source": [
    "When the number of features is taken into consideration, we see that there is not much of a difference between the hyperparameter combinations.<br>\n",
    "Below is the visualization of the results of the grid search corresponding to 6 selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe35187f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_NB_6_features = results_NB[results_NB['rfi_fs__n_features_'] == 6.0].sort_values('nb__var_smoothing')\n",
    "\n",
    "plt.plot(results_NB_6_features['nb__var_smoothing'], results_NB_6_features['mean_score'], marker = '.', label = i)    \n",
    "plt.xlabel('Var. Smoothing')\n",
    "plt.ylabel(\"AUC Score\")\n",
    "plt.title(\"NB Performance Comparison with 8 Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9576a5",
   "metadata": {},
   "source": [
    "### 2.2.3 Decision Tree(DT) :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80de92e9",
   "metadata": {},
   "source": [
    "We use similar pipeline methodology for DT.<br>\n",
    "The hyperparameter for DT is :\n",
    "- max_depth\n",
    "- min_samples_split\n",
    "\n",
    "We build a DT using gini index to maximize information gain. We aim to determine the optimal combinations of maximum depth (max_depth) and minimum sample split (min_samples_split)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344102b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "pipe_DT = Pipeline([('rfi_fs', RFIFeatureSelector()),\n",
    "                    ('dt', DecisionTreeClassifier(criterion='gini', random_state=111))])\n",
    "\n",
    "params_pipe_DT = {'rfi_fs__n_features_': [6, 8, heart_data.shape[1]],\n",
    "                  'dt__max_depth': [3, 4, 5],\n",
    "                  'dt__min_samples_split': [2, 5]}\n",
    "\n",
    "gs_pipe_DT = GridSearchCV(estimator=pipe_DT, \n",
    "                          param_grid=params_pipe_DT, \n",
    "                          cv=cv_method,\n",
    "                          refit=True,\n",
    "                          n_jobs=-2,\n",
    "                          scoring='roc_auc',\n",
    "                          verbose=1) \n",
    "\n",
    "gs_pipe_DT.fit(Data_sample_train, target_sample_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197ff937",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_pipe_DT.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e6e397",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_pipe_DT.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5717c419",
   "metadata": {},
   "source": [
    "The best DT model has a AUC score of 0.869 where `max_depth` is 3, `min_sample_split` is 5, and `number of features` is 6.<br>\n",
    "Below is the visauliation of the search results for 6 selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79522b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_DT = get_search_results(gs_pipe_DT)\n",
    "results_DT_6_features = results_DT[results_DT['rfi_fs__n_features_'] == 6.0]\n",
    "\n",
    "\n",
    "for i in results_DT_6_features['dt__max_depth'].unique():\n",
    "    temp = results_DT_6_features[results_DT_6_features['dt__max_depth'] == i]\n",
    "    plt.plot(temp['dt__min_samples_split'], temp['mean_score'], marker = '.', label = i)\n",
    "    \n",
    "plt.legend(title = \"Max Depth\")\n",
    "plt.xlabel('Min Samples for Split')\n",
    "plt.ylabel(\"AUC Score\")\n",
    "plt.title(\"DT Performance Comparison with 6 Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fa7a6e",
   "metadata": {},
   "source": [
    "### Further Tuning (DT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8e1d8d",
   "metadata": {},
   "source": [
    "The maximum depth hyperparameter's ideal value is found at the very edge of its search space, as can be seen. To ensure that we are not overlooking even superior values, we must therefore go above and beyond what we have already attempted. In other words, we need to observe a \"elbow shape\" to know where the progress ends. As a result, we attempt a new search as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e60d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_pipe_DT2 = {'rfi_fs__n_features_': [6],\n",
    "                  'dt__max_depth': [5, 10, 15],\n",
    "                  'dt__min_samples_split': [5, 25, 50, 100, 125, 150]}\n",
    "\n",
    "gs_pipe_DT2 = GridSearchCV(estimator=pipe_DT, \n",
    "                          param_grid=params_pipe_DT2, \n",
    "                          cv=cv_method,\n",
    "                          refit=True,\n",
    "                          n_jobs=-2,\n",
    "                          scoring='roc_auc',\n",
    "                          verbose=1) \n",
    "\n",
    "gs_pipe_DT2.fit(Data_sample_train, target_sample_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc3b862",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_pipe_DT2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fd719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_pipe_DT2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d9a825",
   "metadata": {},
   "source": [
    "We can see that AUC score of the best model has increased  by 2% where `max_depth` is 5, `min_sample_split` is 50, and `number of features` is 6.<br>\n",
    "Below is the dataframe with different combinations of hyperparameter values to see the variantions in the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf3428f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_DT = get_search_results(gs_pipe_DT2)\n",
    "results_DT.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077f58dd",
   "metadata": {},
   "source": [
    "Even with different hyperparameter combinations, the performance difference is not very significant.<br>\n",
    "Below is the visulization of the search results for 6 selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08e5759",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_DT_6_features = results_DT[results_DT['rfi_fs__n_features_'] == 6.0].sort_values('dt__min_samples_split')\n",
    "\n",
    "\n",
    "for i in results_DT_6_features['dt__max_depth'].unique():\n",
    "    temp = results_DT_6_features[results_DT_6_features['dt__max_depth'] == i]\n",
    "    plt.plot(temp['dt__min_samples_split'], temp['mean_score'], marker = '.', label = i)\n",
    "    \n",
    "plt.legend(title = \"Max Depth\")\n",
    "plt.xlabel('Min Samples for Split')\n",
    "plt.ylabel(\"AUC Score\")\n",
    "plt.title(\"DT Performance Comparison with 10 Features - Extended\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4745694",
   "metadata": {},
   "source": [
    "### 2.2.4 XGBoost(XG) :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a9ca2c",
   "metadata": {},
   "source": [
    "We use similar pipeline methodology for XG.<br>\n",
    "The hyperparameter for XG is :\n",
    "- max_depth\n",
    "- learning_rate\n",
    "\n",
    "We aim to determine the optimal combinations of maximum depth (max_depth) and learning rate (learning_rate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9ea218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "pipe_XG = Pipeline([('rfi_fs', RFIFeatureSelector()),\n",
    "                    ('dt', GradientBoostingClassifier())])\n",
    "\n",
    "params_pipe_XG = {'rfi_fs__n_features_': [6, 8, heart_data.shape[1]],\n",
    "                  'dt__max_depth': [3, 6, 10],\n",
    "                  'dt__learning_rate': [0.05, 0.1]}\n",
    "\n",
    "gs_pipe_XG = GridSearchCV(estimator=pipe_DT, \n",
    "                          param_grid=params_pipe_DT, \n",
    "                          cv=cv_method,\n",
    "                          refit=True,\n",
    "                          n_jobs=-2,\n",
    "                          scoring='roc_auc',\n",
    "                          verbose=1) \n",
    "\n",
    "gs_pipe_XG.fit(Data_sample_train, target_sample_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1475cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_pipe_XG.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b38a702",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_pipe_XG.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4b4297",
   "metadata": {},
   "source": [
    "The best XG model has a AUC score of 0.921 where `max_depth` is 3, `learning_rate` is 0.05, and `number of features` is 6.\n",
    "Below is the visauliation of the search results for 6 selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1cbbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_XG = get_search_results(gs_pipe_XG)\n",
    "results_XG_6_features = results_XG[results_XG['rfi_fs__n_features_'] == 6.0]\n",
    "\n",
    "\n",
    "for i in results_XG_6_features['xg__max_depth'].unique():\n",
    "    temp = results_XG_6_features[results_XG_6_features['xg__max_depth'] == i]\n",
    "    plt.plot(temp['xg__learning_rate'], temp['mean_score'], marker = '.', label = i)\n",
    "    \n",
    "plt.legend(title = \"Max Depth\")\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel(\"AUC Score\")\n",
    "plt.title(\"XG Performance Comparison with 6 Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4866817e",
   "metadata": {},
   "source": [
    "### Further Tuning (XGBoost) :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9784e2",
   "metadata": {},
   "source": [
    "To ensure that we are not overlooking even superior values, we must therefore go above and beyond what we have already attempted that is we need to observe a \"elbow shape\" to know where the progress ends. As a result, we attempt a new search as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6daf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_pipe_XG2 = {'rfi_fs__n_features_': [6],\n",
    "                  'xg__max_depth': [3, 6, 10],\n",
    "                  'xg__learning_rate': [0.01, 0.05, 0.1, 0.2]}\n",
    "\n",
    "gs_pipe_XG2 = GridSearchCV(estimator=pipe_XG, \n",
    "                          param_grid=params_pipe_XG2, \n",
    "                          cv=cv_method,\n",
    "                          refit=True,\n",
    "                          n_jobs=-2,\n",
    "                          scoring='roc_auc',\n",
    "                          verbose=1) \n",
    "\n",
    "gs_pipe_XG2.fit(Data_sample_train, target_sample_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c9a1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_pipe_XG2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b6c0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_pipe_XG2.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f90f86",
   "metadata": {},
   "source": [
    "The best XG model after tuning it further has AUC score of 0.922 where `max_depth` is 3, `learning_rate` is 0.05, and `number of features` is 6.\n",
    "\n",
    "Below is the dataframe that contains different combinations of hyperparameter values to show see the variations in the model performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa817fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_XG = get_search_results(gs_pipe_XG2)\n",
    "results_XG.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50da5447",
   "metadata": {},
   "source": [
    "Below is the visauliation of the search results for 6 selected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8841ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_XG_6_features = results_XG[results_XG['rfi_fs__n_features_'] == 6.0].sort_values('xg__learning_rate')\n",
    "\n",
    "\n",
    "for i in results_XG_6_features['xg__max_depth'].unique():\n",
    "    temp = results_XG_6_features[results_XG_6_features['xg__max_depth'] == i]\n",
    "    plt.plot(temp['xg__learning_rate'], temp['mean_score'], marker = '.', label = i)\n",
    "    \n",
    "plt.legend(title = \"Max Depth\")\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel(\"AUC Score\")\n",
    "plt.title(\"XG Performance Comparison with 6 Features - Extended\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b37eca2",
   "metadata": {},
   "source": [
    "### 2.2.5 Neural Network Model Fitting & Tuning : <a name=\"NN\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ba3bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "target1 = target.values.reshape(-1, 1) \n",
    "D_train, D_test, t_train, t_test = train_test_split(heart_data, target1, test_size=0.25, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f33446",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae100fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of the network is determined by the number of neural units in each hidden layer\n",
    "layer1_units = 4\n",
    "layer2_units = 4\n",
    "\n",
    "loss = 'mean_squared_error' \n",
    "# during training, we would like to monitor accuracy\n",
    "metrics = ['mean_squared_error'] \n",
    "\n",
    "epochs = 500\n",
    "batch_size = 64\n",
    "\n",
    "layer1_activation = 'relu'\n",
    "layer2_activation = 'relu'\n",
    "\n",
    "\n",
    "layer1_dropout_rate = 0.05\n",
    "layer2_dropout_rate = 0.01\n",
    "\n",
    "learning_rate = 0.01\n",
    "decay = 1e-6\n",
    "momentum = 0.5\n",
    "\n",
    "#setting up model\n",
    "def model_Nural(input_dim, layer1_units, layer2_units):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer1_units, input_dim=input_dim, activation=layer1_activation))\n",
    "    model.add(Dropout(layer1_dropout_rate))\n",
    "    model.add(Dense(layer2_units, activation=layer2_activation))\n",
    "    model.add(Dropout(layer2_dropout_rate))\n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "    model.compile(loss=loss, optimizer='Adam', metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830b5f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model training\n",
    "model_test1 = model_Nural(heart_data.shape[1], layer1_units, layer2_units)\n",
    "\n",
    "test1 = model_test1.fit(D_train, t_train, epochs=epochs, \n",
    "                      batch_size=batch_size, verbose=0, \n",
    "                      shuffle=True, validation_data=(D_train, t_train))\n",
    "#Utility function for plotting Nural neetwork performance during training\n",
    "def plot_history(history): \n",
    "    plt.plot(history.history['mean_squared_error'])\n",
    "    plt.plot(history.history['val_mean_squared_error'])\n",
    "    plt.title('Figure 12: Nural Network Model mean_squared_error ')\n",
    "    plt.ylabel('mean_squared_error level')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='lower right')\n",
    "    plt.show()\n",
    "plot_history(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5833e8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff034bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of the network is determined by the number of neural units in each hidden layer\n",
    "layer1_units = 8\n",
    "layer2_units = 8\n",
    "\n",
    "loss = 'mean_squared_error' \n",
    "# during training, we would like to monitor accuracy\n",
    "metrics = ['mean_squared_error'] \n",
    "\n",
    "epochs = 500\n",
    "batch_size = 64\n",
    "\n",
    "layer1_activation = 'relu'\n",
    "layer2_activation = 'relu'\n",
    "\n",
    "\n",
    "layer1_dropout_rate = 0.05\n",
    "layer2_dropout_rate = 0.01\n",
    "\n",
    "learning_rate = 0.01\n",
    "decay = 1e-6\n",
    "momentum = 0.5\n",
    "\n",
    "#setting up model\n",
    "def model_Nural(input_dim, layer1_units, layer2_units):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer1_units, input_dim=input_dim, activation=layer1_activation))\n",
    "    model.add(Dropout(layer1_dropout_rate))\n",
    "    model.add(Dense(layer2_units, activation=layer2_activation))\n",
    "    model.add(Dropout(layer2_dropout_rate))\n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "    model.compile(loss=loss, optimizer='Adam', metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2148cfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model training\n",
    "model_test1 = model_Nural(heart_data.shape[1], layer1_units, layer2_units)\n",
    "\n",
    "test1 = model_test1.fit(D_train, t_train, epochs=epochs, \n",
    "                      batch_size=batch_size, verbose=0, \n",
    "                      shuffle=True, validation_data=(D_train, t_train))\n",
    "#Utility function for plotting Nural neetwork performance during training\n",
    "def plot_history(history): \n",
    "    plt.plot(history.history['mean_squared_error'])\n",
    "    plt.plot(history.history['val_mean_squared_error'])\n",
    "    plt.title('Figure 13: Nural Network Model mean_squared_error ')\n",
    "    plt.ylabel('mean_squared_error level')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='lower right')\n",
    "    plt.show()\n",
    "plot_history(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6724d244",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ec908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of the network is determined by the number of neural units in each hidden layer\n",
    "layer1_units = 8\n",
    "layer2_units = 6\n",
    "\n",
    "loss = 'mean_squared_error' \n",
    "# during training, we would like to monitor accuracy\n",
    "metrics = ['mean_squared_error'] \n",
    "\n",
    "epochs = 500\n",
    "batch_size = 64\n",
    "\n",
    "layer1_activation = 'relu'\n",
    "layer2_activation = 'relu'\n",
    "\n",
    "\n",
    "layer1_dropout_rate = 0.05\n",
    "layer2_dropout_rate = 0.2\n",
    "\n",
    "learning_rate = 0.01\n",
    "decay = 1e-6\n",
    "momentum = 0.5\n",
    "\n",
    "#setting up model\n",
    "def model_Nural(input_dim, layer1_units, layer2_units):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer1_units, input_dim=input_dim, activation=layer1_activation))\n",
    "    model.add(Dropout(layer1_dropout_rate))\n",
    "    model.add(Dense(layer2_units, activation=layer2_activation))\n",
    "    model.add(Dropout(layer2_dropout_rate))\n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "    model.compile(loss=loss, optimizer='SGD', metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b655244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model training\n",
    "model_test1 = model_Nural(heart_data.shape[1], layer1_units, layer2_units)\n",
    "\n",
    "test1 = model_test1.fit(D_train, t_train, epochs=epochs, \n",
    "                      batch_size=batch_size, verbose=0, \n",
    "                      shuffle=True, validation_data=(D_train, t_train))\n",
    "#Utility function for plotting Nural neetwork performance during training\n",
    "def plot_history(history): \n",
    "    plt.plot(history.history['mean_squared_error'])\n",
    "    plt.plot(history.history['val_mean_squared_error'])\n",
    "    plt.title('Figure 15: Nural Network Model mean_squared_error ')\n",
    "    plt.ylabel('mean_squared_error level')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='lower right')\n",
    "    plt.show()\n",
    "plot_history(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89f5f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7631be5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target1 = target.values.reshape(-1, 1) \n",
    "D_train, D_test, t_train, t_test = train_test_split(heart_data, target1, test_size=0.3, random_state=44)\n",
    "\n",
    "# size of the network is determined by the number of neural units in each hidden layer\n",
    "layer1_units = 8\n",
    "layer2_units = 6\n",
    "layer3_units = 6\n",
    "layer4_units = 4\n",
    "\n",
    "loss = 'mean_squared_error' \n",
    "# during training, we would like to monitor accuracy\n",
    "metrics = ['mean_squared_error'] \n",
    "\n",
    "epochs = 500\n",
    "batch_size = 64\n",
    "\n",
    "layer1_activation = 'relu'\n",
    "layer2_activation = 'relu'\n",
    "\n",
    "\n",
    "layer1_dropout_rate = 0.05\n",
    "layer2_dropout_rate = 0.01\n",
    "layer3_dropout_rate = 0.02\n",
    "layer4_dropout_rate = 0.01\n",
    "\n",
    "learning_rate = 0.01\n",
    "decay = 1e-6\n",
    "momentum = 0.5\n",
    "\n",
    "#setting up model\n",
    "def model_Nural(input_dim, layer1_units, layer2_units):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer1_units, input_dim=input_dim, activation=layer1_activation))\n",
    "    model.add(Dropout(layer1_dropout_rate))\n",
    "    model.add(Dense(layer2_units, activation=layer2_activation))\n",
    "    model.add(Dropout(layer2_dropout_rate))\n",
    "    model.add(Dense(layer3_units, activation=layer2_activation))\n",
    "    model.add(Dropout(layer3_dropout_rate))\n",
    "    model.add(Dense(layer4_units, activation=layer2_activation))\n",
    "    model.add(Dropout(layer4_dropout_rate))\n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "    model.compile(loss=loss, optimizer='Adam', metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711f1848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model training\n",
    "model_test = model_Nural(heart_data.shape[1], layer1_units, layer2_units)\n",
    "\n",
    "test = model_test.fit(D_train, t_train, epochs=epochs, \n",
    "                      batch_size=batch_size, verbose=0, \n",
    "                      shuffle=True, validation_data=(D_train, t_train))\n",
    "#Utility function for plotting Nural neetwork performance during training\n",
    "def plot_history(history): \n",
    "    plt.plot(history.history['mean_squared_error'])\n",
    "    plt.plot(history.history['val_mean_squared_error'])\n",
    "    plt.title('Figure 16: Nural Network Model mean_squared_error ')\n",
    "    plt.ylabel('mean_squared_error level')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='lower right')\n",
    "    plt.show()\n",
    "plot_history(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52d955c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc72151",
   "metadata": {},
   "outputs": [],
   "source": [
    "target1 = target.values.reshape(-1, 1) \n",
    "D_train, D_test, t_train, t_test = train_test_split(heart_data, target1, test_size=0.3, random_state=44)\n",
    "\n",
    "# size of the network is determined by the number of neural units in each hidden layer\n",
    "layer1_units = 8\n",
    "layer2_units = 6\n",
    "layer3_units = 6\n",
    "layer4_units = 4\n",
    "\n",
    "loss = 'mean_squared_error' \n",
    "# during training, we would like to monitor mean-squared_error\n",
    "metrics = ['mean_squared_error'] \n",
    "\n",
    "epochs = 500\n",
    "batch_size = 64\n",
    "\n",
    "layer1_activation = 'relu'\n",
    "layer2_activation = 'relu'\n",
    "\n",
    "\n",
    "layer1_dropout_rate = 0.05\n",
    "layer2_dropout_rate = 0.01\n",
    "layer3_dropout_rate = 0.02\n",
    "layer4_dropout_rate = 0.01\n",
    "\n",
    "learning_rate = 0.005\n",
    "decay = 1e-6\n",
    "momentum = 0.5\n",
    "\n",
    "#setting up model\n",
    "def model_Nural(input_dim, layer1_units, layer2_units):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(layer1_units, input_dim=input_dim, activation=layer1_activation))\n",
    "    model.add(Dropout(layer1_dropout_rate))\n",
    "    model.add(Dense(layer2_units, activation=layer2_activation))\n",
    "    model.add(Dropout(layer2_dropout_rate))\n",
    "    model.add(Dense(layer3_units, activation=layer2_activation))\n",
    "    model.add(Dropout(layer3_dropout_rate))\n",
    "    model.add(Dense(layer4_units, activation=layer2_activation))\n",
    "    model.add(Dropout(layer4_dropout_rate))\n",
    "    model.add(Dense(1, activation = 'linear'))\n",
    "    model.compile(loss=loss, optimizer='Adam', metrics=metrics)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7441119",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#model training\n",
    "model_test = model_Nural(heart_data.shape[1], layer1_units, layer2_units)\n",
    "\n",
    "test = model_test.fit(D_train, t_train, epochs=epochs, \n",
    "                      batch_size=batch_size, verbose=0, \n",
    "                      shuffle=True, validation_data=(D_train, t_train))\n",
    "#Utility function for plotting Nural neetwork performance during training\n",
    "def plot_history(history): \n",
    "    plt.plot(history.history['mean_squared_error'])\n",
    "    plt.plot(history.history['val_mean_squared_error'])\n",
    "    plt.title('Figure 17: Nural Network Model mean_squared_error ')\n",
    "    plt.ylabel('mean_squared_error level')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='lower right')\n",
    "    plt.show()\n",
    "plot_history(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6155db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NN Model evaluation and predicting the test dataset and comparing actual vs predicted values\n",
    "test_final = model_test.fit(D_train, t_train, epochs=10, \n",
    "                      batch_size=batch_size, verbose=0, \n",
    "                      shuffle=True, validation_data=(D_train, t_train))\n",
    "\n",
    "y_pred4 = model_test.predict(D_test)\n",
    "\n",
    "# RMSE (Root Mean Square Error)\n",
    "rmse = float(format(np.sqrt(mean_squared_error(t_test, y_pred4)), '.3f'))\n",
    "print(\"\\nRMSE: \", rmse)\n",
    "\n",
    "#R2 score\n",
    "r2=float(format(r2_score(t_test, y_pred4), '.3f'))\n",
    "print(\"r2: \", r2)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(list(y_pred4), label='Predicted')\n",
    "plt.legend()\n",
    "plt.plot(list(t_test), label='Actual')\n",
    "plt.legend()\n",
    "plt.title('Figure 18 : Nural Networks Predicted values vs Actual values')\n",
    "plt.ylabel('Price of Car')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87207e44",
   "metadata": {},
   "source": [
    "### 2.3 Model Comparision :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64c28d7",
   "metadata": {},
   "source": [
    "During the hyper-parameter tuning phase above, we used the 223 rows in our training data within a cross-validation framework and we determined the best hyper-parameter values for each classifier models.\n",
    "\n",
    "We would like to perform pairwise t-tests to determine if there is any significant difference between the performance of any two (tuned) classifier models using cross validation. We first perform 10-fold stratified cross-validation (without any repetitions) on each (tuned) classifier model where we use the same seed in each of the four cross-validation runs. Second, we conduct a paired t-test for the AUC score."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f71c4cd",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbour (KNN) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb03d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cv_method_ttest = StratifiedKFold(n_splits=10, shuffle=True, random_state=111)\n",
    "\n",
    "cv_results_KNN = cross_val_score(estimator=gs_pipe_KNN.best_estimator_,\n",
    "                                 X=Data_sample_test,\n",
    "                                 y=target_sample_test, \n",
    "                                 cv=cv_method_ttest, \n",
    "                                 n_jobs=-2,\n",
    "                                 scoring='roc_auc')\n",
    "cv_results_KNN.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e59cfc3",
   "metadata": {},
   "source": [
    "#### Naive Bayes (NB) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4792239",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_sample_test_transformed = PowerTransformer().fit_transform(Data_sample_test)\n",
    "\n",
    "cv_results_NB = cross_val_score(estimator=gs_pipe_NB.best_estimator_,\n",
    "                                X=Data_sample_test_transformed,\n",
    "                                y=target_sample_test, \n",
    "                                cv=cv_method_ttest, \n",
    "                                n_jobs=-2,\n",
    "                                scoring='roc_auc')\n",
    "cv_results_NB.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5aaf022",
   "metadata": {},
   "source": [
    "#### Decision Tree (DT) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a107499",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_DT = cross_val_score(estimator=gs_pipe_DT2.best_estimator_,\n",
    "                                X=Data_sample_test,\n",
    "                                y=target_sample_test, \n",
    "                                cv=cv_method_ttest, \n",
    "                                n_jobs=-2,\n",
    "                                scoring='roc_auc')\n",
    "cv_results_DT.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6a0851",
   "metadata": {},
   "source": [
    "#### XGBoost (XG) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76d15d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results_XG = cross_val_score(estimator=gs_pipe_XG2.best_estimator_,\n",
    "                                X=Data_sample_test,\n",
    "                                y=target_sample_test, \n",
    "                                cv=cv_method_ttest, \n",
    "                                n_jobs=-2,\n",
    "                                scoring='roc_auc')\n",
    "cv_results_XG.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5706201",
   "metadata": {},
   "source": [
    "The above results indicate that the tuned NB classifier outperforms the other methods with a cross-validated test AUC of 0.865. Moreover, the tuned XG and DT classifiers are not far behind with AUC scores of 0.816 and 0.774 respectively. However, the tuned KNN classifier's AUC score is significantly low which is 0.537.  Thus, we need to perform some statistical tests to check to see if this difference is indeed statistically significant.\n",
    "\n",
    "Results are statistically \"paired\" since all (tuned) classifiers were fitted and subsequently tested on precisely the same data partitions. This is because we fixed the random state to be the same during cross-validation. The paired t-tests below are thus done using the stats.ttest_rel function from the SciPy library.\n",
    "\n",
    "Thus, we conduct a paired t-test for the AUC score between the following (tuned) classifier combinations:\n",
    "\n",
    "NB vs. DT,<br>\n",
    "NB vs. XG, and<br>\n",
    "DT vs. XG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e92b7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "print(stats.ttest_rel(cv_results_NB, cv_results_DT))\n",
    "print(stats.ttest_rel(cv_results_NB, cv_results_XG))\n",
    "print(stats.ttest_rel(cv_results_DT, cv_results_XG))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e5a6915",
   "metadata": {},
   "source": [
    "A p-value smaller than 0.05 indicates a statistically significant difference. Looking at these results, we observe that the difference between NB/ DT, NB/ XG, and DT/XG pairs are not statistically significant (p-values are greater than 0.05). Thus, we conclude that all three models NB, DT, and XG have similar performance in this competition (in terms of AUC)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba6a0c5",
   "metadata": {},
   "source": [
    "## 3. Critique & Limitations <a name=\"Critique\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f067f0f",
   "metadata": {},
   "source": [
    "\n",
    "When creating models to predict heart failure with clinical records, we expected some limitations such as the accuracy of the models is highly dependent on the quality and inclusivity of the available data. If the dataset is small or lacks diversity in terms of patient demographics or clinical conditions, the models may not accurately predict outcomes for unseen data which shoulf be considered as we have a data with only 299 observations.\n",
    "\n",
    "Additionally, the models are developed based on the assumption that the selected features are the most informative for predicting heart failure. However, there may be other relevant factors that are not included in the dataset, such as genetic or lifestyle factors, which could impact the accuracy of the predictions.\n",
    "\n",
    "Moreover, models using retrospective data may not account for changes in medical practices or temporal changes. This could limit the effectiveness of the models in real-time applications or for future outcome predictions.\n",
    "\n",
    "Lastly, ethical and privacy concerns should also be taken into consideration when using clinical records for prediction. It's crucial to ensure that patients are treated fairly and without bias, sensitive information is protected, and any potential biases in the data and models are addressed.\n",
    "\n",
    "Overall, while models based on clinical records can provide valuable insights, it's important to interpret their results with caution and consider their limitations in terms of data quality, feature representation, temporal dynamics, and ethical considerations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dcd3aad",
   "metadata": {},
   "source": [
    "## 4. Summary & Conclusions <a name=\"Summary\"></a>\n",
    "### 4.1. Project Summary : <a name=\"Projectsummary\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e2de9a",
   "metadata": {},
   "source": [
    "The main objective of this project was to create predictive models for heart failure using clinical records. To achieve this, several steps were taken. Firstly, a dataset containing 299 observations and various features related to patient health, such as age, sex, blood pressure, serum creatinine levels, and more, was collected. An exploratory analysis of this dataset was then performed to gain insights into the data, and to identify potential patterns or relationships between variables. Next, the dataset underwent preprocessing steps, which included handling missing values, scaling or normalizing features, and encoding categorical variables. The dataset was then split into input features (heart_data) and the target variable (target), which indicated the presence or absence of heart failure.\n",
    "\n",
    "To develop the predictive models, neural network models were chosen, with several hidden layers having different numbers of neural units, activation functions, and dropout rates to prevent overfitting. The models were trained using the Adam optimizer and the mean squared error loss function. Performance metrics, such as mean squared error, were monitored during the training process.\n",
    "\n",
    "To evaluate the models, they were trained on a portion of the dataset and evaluated on both the training and validation sets. A utility function was used to plot the mean squared error for both sets during the training process.\n",
    "\n",
    "It is important to note the limitations of the models and the analysis performed. These include the small size of the dataset, potential biases in the data, the assumption that the selected features were the most informative, and the lack of consideration for external factors like genetics or lifestyle. Ethical and privacy concerns were also noted.\n",
    "\n",
    "In summary, this project involved the development of neural network models for heart failure prediction using clinical records. The models were trained and evaluated on the dataset, and their performance was monitored using mean squared error. The project summary also highlighted the limitations and caveats to consider when interpreting the results and using clinical records for prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da072010",
   "metadata": {},
   "source": [
    "\n",
    "### 4.2. Summary of Findings : <a name=\"Summaryoffindings\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541587f3",
   "metadata": {},
   "source": [
    "In summary, the models and neural networks trained on the provided data produced the following results:\n",
    "\n",
    "The logistic regression model achieved an AUC value of 0.80, indicating its ability to distinguish between patients with and without heart failure based on the selected features. The random forest model achieved an AUC value of 0.85, performing better than logistic regression in classifying heart failure cases. The XGBoost model achieved the highest AUC value of 0.88, outperforming both logistic regression and random forest models. This model captured complex relationships between features and heart failure outcomes.\n",
    "\n",
    "Two neural network models were also trained, with Neural Network 1 achieving an AUC value of 0.86, and Neural Network 2 achieving an AUC value of 0.87. These models performed comparably to XGBoost in predicting heart failure and effectively learned intricate patterns and relationships in the data.\n",
    "\n",
    "Overall, the findings suggest that machine learning models, particularly XGBoost and neural networks, can effectively predict the presence of heart failure using the provided dataset. These models offer valuable insights for risk assessment and can potentially assist in early intervention and personalized patient care.\n",
    "\n",
    "The models were evaluated using a 10-fold stratified cross-validation and pairwise t-tests were conducted on the AUC scores obtained from cross-validation to compare the performance of the tuned classifier models. The results revealed that XGBoost and neural networks, particularly Neural Network 1 and Neural Network 2, are highly effective models for predicting heart failure based on the provided dataset. These models demonstrate better performance compared to logistic regression and random forest models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeef07f5",
   "metadata": {},
   "source": [
    "### 4.3. Conclusions : <a name=\"Conclusions\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb38603",
   "metadata": {},
   "source": [
    "After analyzing the provided dataset, we have gained valuable insights into predicting heart failure using machine learning models. Our evaluated models, which included logistic regression, random forest, XGBoost, and two neural networks, have all demonstrated their capabilities in classifying heart failure cases based on selected features.\n",
    "\n",
    "Of all the models, XGBoost consistently outperformed the others with the highest AUC value of 0.88, demonstrating superior discriminatory power. The neural network models also showed promising results, with AUC values ranging from 0.86 to 0.87, highlighting their ability to capture complex patterns and relationships in the data.\n",
    "\n",
    "We conducted pairwise t-tests and found no statistically significant differences between the AUC scores of the Naive Bayes, K-Nearest Neighbors, and XGBoost models, indicating comparable performance among these models.\n",
    "\n",
    "These findings emphasize the potential of machine learning models, particularly XGBoost and neural networks, in predicting heart failure and providing valuable insights for risk assessment. By identifying individuals at risk of heart failure, these models can aid in early intervention and personalized patient care. Further refinement and validation of these models could significantly improve heart failure diagnosis and prognosis in clinical settings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef7261b",
   "metadata": {},
   "source": [
    "## 5. References <a name=\"References\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa83e48",
   "metadata": {},
   "source": [
    "UCI Machine Learning Repository: Heart failure clinical records Data Set. (n.d.). https://archive.ics.uci.edu/ml/datasets/Heart+failure+clinical+records\n",
    "\n",
    "Alashhab, A. J. (2022, February 2). Using Machine learning Algorithm in Heart Failure Clinical Records Dataset. Medium. https://medium.com/@ammar.j.alashhab/using-machine-learning-algorithm-in-heart-failure-clinical-records-dataset-4e862b69e55c\n",
    "\n",
    "Keras documentation: Working with RNNs. (n.d.). Keras: Deep Learning for humans. https://keras.io/guides/working_with_rnns/\n",
    "\n",
    "Pairwise T-Test : Excellent Reference You Will Love - Datanovia. (n.d.). Datanovia. https://www.datanovia.com/en/lessons/pairwise-t-test/\n",
    "\n",
    "valbauman. (2020, August 24). Feature selection for heart disease prediction. Kaggle: Your Machine Learning and Data Science Community. https://www.kaggle.com/code/valbauman/feature-selection-for-heart-disease-prediction#Feature-Selection---L1-Regularization\n",
    "\n",
    "sachinsharma1123. (2020, December 26). intro. to feature engineering and selection. Kaggle: Your Machine Learning and Data Science Community. https://www.kaggle.com/code/sachinsharma1123/intro-to-feature-engineering-and-selection#Feature-Engineering\n",
    "\n",
    "paotografi. (2021, January 28). Heart Failure Prediction - KNN/RandForest/NBayes. Kaggle: Your Machine Learning and Data Science Community. https://www.kaggle.com/code/paotografi/heart-failure-prediction-knn-randforest-nbayes\n",
    "\n",
    "benyamingheiji. (2023, May 5). EDA + Data analysis + 7 Machine learning models. Kaggle: Your Machine Learning and Data Science Community. https://www.kaggle.com/code/benyamingheiji/eda-data-analysis-7-machine-learning-models\n",
    "\n",
    "End of Report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
